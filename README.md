[![Review Assignment Due Date](https://classroom.github.com/assets/deadline-readme-button-22041afd0340ce965d47ae6ef1cefeee28c7c493a6346c4f15d667ab976d596c.svg)](https://classroom.github.com/a/w3FoW0fO)

# EE260C_LAB1: Perception

Please refer to the instructions [here](https://docs.google.com/document/d/1BvQ9ztEvxDwsHv-RWEy2EOA7kdAonzdkbJIuQSB1nJI/edit?usp=sharing)

## Lab 1 - Divyank Shah (dshah048)

### Sensor Setup

1. LiDAR - 64 Channels
2. Left Camera - 1280 x 720
3. Right Camera - 1280 x 720
4. GNNS (GPS)

### Model Used

PointPillars from MMDetection3D

#### Execution Verification on Kitti Dataset

![Kitti Verification - Lidar](./images/kitti_verification.png)

### Visualize Ground Truth

![Ground Truth - Lidar](./images/lidar_ground_truth.png)
![Ground Truth - Lidar](./images/lidar_ground_truth_2.png)

![Ground Truth - Camera](./images/camera_ground_truth.png)
![Ground Truth - Camera](./images/camera_ground_truth_2.png)
![Ground Truth - Camera](./images/camera_ground_truth_3.png)

### PointPillars Detection

![Predictions - Lidar](./images/lidar_pointpillars.png)

![Predictions - Camera](./images/camera_pointpillars.png)
![Predictions - Camera](./images/camera_pointpillars_2.png)
![Predictions - Camera](./images/pointpillars.png)
